{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Cancer Survival Prediction Endpoint Demo\n",
    "\n",
    "In this endpoint demo notebook, we demonstrate how to send inference requests to an pre-deployed endpoint and get the model response.\n",
    "\n",
    "To find more details of an end-to-end solution for data processing, feature store, model training and deployement using SageMaker, check out the solution notebook `xxxxxxx.ipynb`. It shows how-to for the following steps: 1/ processing multi-modal data (genomic, clinical, medical imaging) to obtain ML features, 2/ ingesting and managing multi-modal features in SageMaker Feature Store, 3/ training a survival status prediction model using PCA and XGBoost, 4/ hosting a model for inference. The exposition in this notebook is deliberately brief. \n",
    "\n",
    ">**<span style=\"color:RED\">Important</span>**: \n",
    ">This solution is for demonstrative purposes only. It is not for clinical use. The ML inference should not be used to inform any clinical decision. The associated notebooks, including the trained model and sample data, are not intended for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in the solution config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SOLUTION_CONFIG = json.load(open(\"stack_outputs.json\"))\n",
    "ROLE = SOLUTION_CONFIG[\"IamRole\"]\n",
    "SOLUTION_BUCKET = SOLUTION_CONFIG[\"SolutionS3Bucket\"]\n",
    "REGION = SOLUTION_CONFIG[\"AWSRegion\"]\n",
    "SOLUTION_NAME = SOLUTION_CONFIG[\"SolutionName\"]\n",
    "BUCKET = SOLUTION_CONFIG[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download and read in the multimodal dataset for inference\n",
    "\n",
    "The test multimodal dataset consists of genomic, clinical and imaging features for X patients. The features have been condensed by PCA from 216 to 65 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "input_data_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/data\"\n",
    "print(\"original data: \")\n",
    "S3Downloader.list(input_data_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data for inference from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = f\"{input_data_bucket}/inference_data.csv\"\n",
    "!aws s3 cp $inference_data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"inference_data.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are principal components computed from 216 features. The original feature vector include features from genomic secondary analysis, clinical health records, and radiomic features from within the lung tumor in computed tomography images. \n",
    "\n",
    "#### Snapshot of data\n",
    "##### Clinical\n",
    "![clinical-data](../images/clinical-data-screenshot.png)\n",
    "\n",
    "#### Genomic\n",
    "![genomic-data](../images/genomic-secondary.png)\n",
    "\n",
    "#### Medical imaging\n",
    "![imaging-data](../images/CT-tumor-overlay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predicting survival status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the demo endpoint successfully, your dataframe columns should be identical to the `df_tabtext_score` as shown in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Predictor\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = SOLUTION_CONFIG[\"SolutionPrefix\"] + \"-demo-endpoint\" \n",
    "\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name = endpoint_name,\n",
    "    sagemaker_session = sagemaker.Session(),\n",
    "    deserializer =  sagemaker.deserializers.JSONDeserializer(),\n",
    "    serializer = sagemaker.serializers.CSVSerializer(),\n",
    ")\n",
    "\n",
    "prediction = predictor.predict(df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the total count of predicted survival status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(prediction))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
