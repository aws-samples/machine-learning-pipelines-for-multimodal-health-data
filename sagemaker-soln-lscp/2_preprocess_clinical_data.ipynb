{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4349d0d5",
   "metadata": {},
   "source": [
    "# Preprocess Clinical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622ce17",
   "metadata": {},
   "source": [
    "The NSCLC Radiogenomic clinical data is in a structured tabular form, as is common for EHR data extracts and health insurance claims data. The NSCLC clinical data consists demographic (gender, ethnicity) and health-behavior (smoking history) information, cancer recurrence status, histology, histopathological grading, pathological TNM staging, and survival outcome. We are going to apply preprocessing steps to transform the categorical features, and remove features that are either redundent or are deemed target leakage features. After the features are preprocessed, we create a feature group in SageMaker Feature Store and ingest the features to the feature store which serves as a central repository for features from all three modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581bf53",
   "metadata": {},
   "source": [
    "## Step 1: Read in the SageMaker JumpStart Solution configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SOLUTION_CONFIG = json.load(open(\"stack_outputs.json\"))\n",
    "SOLUTION_BUCKET = SOLUTION_CONFIG[\"SolutionS3Bucket\"]\n",
    "REGION = SOLUTION_CONFIG[\"AWSRegion\"]\n",
    "SOLUTION_PREFIX = SOLUTION_CONFIG[\"SolutionPrefix\"]\n",
    "SOLUTION_NAME = SOLUTION_CONFIG[\"SolutionName\"]\n",
    "BUCKET = SOLUTION_CONFIG[\"S3Bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6e829",
   "metadata": {},
   "source": [
    "## Step 2: Download and read in the clinical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a9806",
   "metadata": {},
   "source": [
    "#### Download the input data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2815e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = \"NSCLCR01Radiogenomic_DATA_LABELS_2018-05-22_1500-shifted.csv\"\n",
    "\n",
    "input_data_bucket = f\"s3://{SOLUTION_BUCKET}-{REGION}/{SOLUTION_NAME}/data\"\n",
    "input_data = f\"{input_data_bucket}/{file_name}\"\n",
    "!aws s3 cp $input_data .\n",
    "\n",
    "data_clinical = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613fdaec",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda93f21",
   "metadata": {},
   "source": [
    "We focus our analysis on cases with prefix `R01-*` in the `Case ID` because they have corresponding medical imaging and genomic data. For feature preprocessing, we do the following:\n",
    "1. Removing imaging date features `CT Date` & `PET Date` as they are irrelevant to the modeling.\n",
    "2. Removing recurrence/survival related features such as `Date of Recurrence` and `Date of Death` as they carry target leakage.\n",
    "3. Transform categorical features with one-hot encoding.\n",
    "4. Drop samples whose `Weightlbs` and `PackYears` are `Not Collected`. \n",
    "5. Fill `NaN` with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97814b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep samples starting with \"R01-*\" as these IDs have corresponding medical imaging data. Delete samples with Case IDs \"AMC-*\". \n",
    "data_clinical = data_clinical[~data_clinical[\"Case ID\"].str.contains(\"AMC\")]\n",
    "\n",
    "# Delete columns with ID and dates\n",
    "list_delete_cols = ['Quit Smoking Year', 'Date of Recurrence', 'Date of Last Known Alive', 'Date of Death', 'CT Date', 'PET Date']\n",
    "data_clinical.drop(list_delete_cols, axis=1, inplace=True)\n",
    "\n",
    "# List of features with catergorical value\n",
    "list_encode_cols = [\"Patient affiliation\", \"Gender\", \"Ethnicity\", \"Smoking status\", \"%GG\", \"Tumor Location (choice=RUL)\", \"Tumor Location (choice=RML)\", \"Tumor Location (choice=RLL)\", \"Tumor Location (choice=LUL)\", \"Tumor Location (choice=LLL)\", \"Tumor Location (choice=L Lingula)\", \"Tumor Location (choice=Unknown)\", \"Histology \", \"Pathological T stage\", \"Pathological N stage\", \"Pathological M stage\", \"Histopathological Grade\", \"Lymphovascular invasion\", \"Pleural invasion (elastic, visceral, or parietal)\", \"EGFR mutation status\", \"KRAS mutation status\", \"ALK translocation status\", \"Adjuvant Treatment\", \"Chemotherapy\", \"Radiation\", \"Recurrence\", \"Recurrence Location\"]\n",
    "\n",
    "# List of features with numeric value\n",
    "list_nonenc_cols = [\"Case ID\", \"Age at Histological Diagnosis\", \"Weight (lbs)\", \"Pack Years\", \"Time to Death (days)\", \"Days between CT and surgery\", \"Survival Status\"]\n",
    "\n",
    "# One-hot encoding of features with categorical value\n",
    "data_clinical_enc = pd.get_dummies(data_clinical[list_encode_cols])\n",
    "\n",
    "data_clinical_nonenc = data_clinical[list_nonenc_cols]\n",
    "\n",
    "# Combine all features\n",
    "data_clin = pd.concat([data_clinical_enc, data_clinical_nonenc], axis=1)\n",
    "\n",
    "# Feature names inside FeatureStore should not have special chars and should be < 64 chars long\n",
    "# Update feature names accordingly\n",
    "\n",
    "l_char = ['-',' ','%','/','<','>','(',')','=',',',':']\n",
    "\n",
    "for col in (data_clin.columns):\n",
    "\n",
    "    if (col == \"Case ID\"):\n",
    "        data_clin.rename(columns={col: col.replace(' ','_')}, inplace = True)\n",
    "        continue\n",
    "\n",
    "    for char in l_char:\n",
    "        if char in col:\n",
    "            data_clin.rename(columns={col: col.replace(char,'')}, inplace = True)\n",
    "            col = col.replace(char,'')\n",
    "            \n",
    "    if (len(col)>=64):\n",
    "        data_clin.rename(columns={col: col[:60]}, inplace = True)\n",
    "        \n",
    "# Change label (survival status) \"Dead\"=1 and \"Alive\"=0 \n",
    "data_clin[\"SurvivalStatus\"].replace({\"Dead\": \"1\", \"Alive\": \"0\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Drop samples with missing values. \n",
    "# Fill NaN with 0. For eg. PackYears for non-smokers is \"NA\". Change it to 0.\n",
    "data_clin = data_clin[data_clin['Weightlbs'] != \"Not Collected\"]\n",
    "data_clin = data_clin[data_clin['PackYears'] != \"Not Collected\"]\n",
    "data_clin.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312a88a",
   "metadata": {},
   "source": [
    "## Step 4: Create SageMaker FeatureStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8243b7",
   "metadata": {},
   "source": [
    "Firstly, we cast the object dtype to string which will then map to String feature type in the SageMaker FeatureStore. We add `record_identifier_feature_name` and `event_time_feature_name` columns to the dataset for creating the feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def cast_object_to_string(data_frame):\n",
    "    for label in data_frame.columns:\n",
    "        print (label)\n",
    "        if data_frame.dtypes[label] == 'object':\n",
    "            data_frame[label] = data_frame[label].astype(\"str\").astype(\"string\")\n",
    "            \n",
    "current_time_sec = int(round(time.time()))\n",
    "\n",
    "# Cast object dtype to string. SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(data_clin)\n",
    "\n",
    "# Record identifier and event time feature names\n",
    "record_identifier_feature_name = \"Case_ID\"\n",
    "event_time_feature_name = \"EventTime\"\n",
    "\n",
    "# Append EventTime feature\n",
    "data_clin[event_time_feature_name] = pd.Series([current_time_sec]*len(data_clin), dtype=\"float64\")\n",
    "\n",
    "## If event time generates NaN\n",
    "data_clin[event_time_feature_name] = data_clin[event_time_feature_name].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9f18c",
   "metadata": {},
   "source": [
    "Next step, we define the FeatureGroup and load feature definitions to the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8261bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "\n",
    "boto_session = boto3.Session(region_name=REGION)\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=REGION)\n",
    "featurestore_runtime = boto_session.client(service_name=\"sagemaker-featurestore-runtime\", region_name=REGION)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")\n",
    "\n",
    "clinical_feature_group_name = f\"{SOLUTION_PREFIX}-clinical-feature-group\"\n",
    "%store clinical_feature_group_name\n",
    "\n",
    "clinical_feature_group = FeatureGroup(name=clinical_feature_group_name, sagemaker_session=feature_store_session)\n",
    "\n",
    "# Load feature definitions to the feature group. SageMaker FeatureStore Python SDK will auto-detect the data schema based on input data.\n",
    "clinical_feature_group.load_feature_definitions(data_frame=data_clin) # output is suppressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd891e5",
   "metadata": {},
   "source": [
    "We create the FeatureGroup for the clinical dataset with both online and offline store enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92953b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "    \n",
    "prefix = \"clinical\"\n",
    "\n",
    "clinical_feature_group.create(\n",
    "    s3_uri=f\"s3://{BUCKET}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=sagemaker.get_execution_role(),\n",
    "    enable_online_store=True\n",
    ")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=clinical_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51566cd0",
   "metadata": {},
   "source": [
    "After the feature group is created, we can ingest the clinical dataset to its feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883882eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_feature_group.ingest(\n",
    "    data_frame=data_clin, max_workers=3, wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132b4d7",
   "metadata": {},
   "source": [
    "## Next Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be956c6",
   "metadata": {},
   "source": [
    "Next, we'll take a look at preparing the clinical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1957",
   "metadata": {},
   "source": [
    "Click here to [continue](./3_preprocess_imaging_data.ipynb)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
